{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b8e0877",
   "metadata": {},
   "source": [
    "# Logistic Regression Code-Along\n",
    "\n",
    "Implement the code-blocks below in order to implement the logistic regressor. We will be using the `breast_cancer` toy dataset which we can directly load from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5ffa271",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63e487fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load dataset\n",
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "\n",
    "# view first 5 rows of predictors\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4da1e446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "437    1\n",
       "248    1\n",
       "380    1\n",
       "494    1\n",
       "379    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view first 5 random samples of target data\n",
    "y.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab7ed68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: select only the \"mean radius\", \"mean texture\", and \"mean perimeter\" predictors for your predictors\n",
    "X = ...\n",
    "\n",
    "# TODO: split into test and training sets\n",
    "X_train, X_test, y_train, y_test = ...\n",
    "\n",
    "# view first 5 rows of training data\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a169f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV - Best Params: {'solver': 'saga', 'penalty': 'l1', 'max_iter': 10000, 'C': np.float64(0.8)}\n",
      "RandomizedSearchCV - Cross-Val Accuracy: 0.89\n",
      "RandomizedSearchCV - Time elapsed: 8.52 seconds\n"
     ]
    }
   ],
   "source": [
    "# Randomly search for the best hyperparameters on a logistic regression model\n",
    "param_dist = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': np.linspace(0.01, 1, 100),\n",
    "    'solver': ['saga'], \n",
    "    'max_iter': [10000]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(LogisticRegression(), param_distributions=param_dist, cv=5, scoring='accuracy', random_state=42)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from random search\n",
    "best_params_random = random_search.best_params_\n",
    "best_score_random = random_search.best_score_\n",
    "\n",
    "print(f\"RandomizedSearchCV - Best Params: {best_params_random}\")\n",
    "print(f\"RandomizedSearchCV - Cross-Val Accuracy: {best_score_random:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb2ba01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV - Coefficients: [[ 3.2243442   0.01382344 -0.53723209]]\n",
      "RandomizedSearchCV - Test Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Use the best model found from RandomizedSearchCV to predict on unseen test data\n",
    "\n",
    "# extract the best estimator\n",
    "best_log = random_search.best_estimator_\n",
    "\n",
    "# predict on testing data\n",
    "log_predictions = best_log.predict(X_test)\n",
    "\n",
    "# evaluate its accuracy\n",
    "test_score = accuracy_score(log_predictions, y_test)\n",
    "\n",
    "print(f\"RandomizedSearchCV - Coefficients: {best_log.coef_}\")\n",
    "print(f\"RandomizedSearchCV - Test Accuracy: {test_score:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c2b4cf",
   "metadata": {},
   "source": [
    "The coefficients above relate to the predictors \"mean radius\", \"mean texture\", and \"mean perimeter.\"\n",
    "\n",
    "Note that positive values indicate a higher log-odds that a tumor is malignant. However, negative values indicate a lower log-odds that a tumor is malignant.\n",
    "\n",
    "Which predictor seems to indicate a higher probability that a tumor is malignant? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f087499f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV - Best Params: {'C': np.float64(0.73), 'max_iter': 10000, 'penalty': 'l1', 'solver': 'saga'}\n",
      "GridSearchCV - Cross-Val Accuracy: 0.89\n"
     ]
    }
   ],
   "source": [
    "# Now we will see why we prefer to use RandomizedSearchCV\n",
    "# Search the grid for the best hyperparameters on a logistic regression model (this will take at least 3 minutes!)\n",
    "grid_search = GridSearchCV(LogisticRegression(), param_grid=param_dist, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from grid search\n",
    "best_params_grid = grid_search.best_params_\n",
    "best_score_grid = grid_search.best_score_\n",
    "\n",
    "print(f\"GridSearchCV - Best Params: {best_params_grid}\")\n",
    "print(f\"GridSearchCV - Cross-Val Accuracy: {best_score_grid:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34d56c3",
   "metadata": {},
   "source": [
    "# Challenge\n",
    "\n",
    "Create a logistic regressor on the `hotel` dataset. Your target variable will be `is_canceled` column, while your predictor will be the `lead_time` column.\n",
    "\n",
    "After creating your model extract best hyperparameters using both `RandomizedSearchCV` and `GridSearchCV`. Evaluate the coefficients and the accuracy of both hyperparameter finding algorithms (we will learn more about classification accuracy metrics tomorrow). \n",
    "\n",
    "Answer the analytical questions listed below as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1211fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the logistic regression model on the `hotel.csv` dataset\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439ae852",
   "metadata": {},
   "source": [
    "## Writeup\n",
    "\n",
    "Answer the analytical questions below using the metrics you've calculated.\n",
    "\n",
    "1) What was the accuracy of your hyperparameters extracted from `GridSearchCV`? Was this any different from `RandomizedSearchCV`? Did the extended run-time of `GridSearchCV` provide huge increases in accuracy?\n",
    "\n",
    "...\n",
    "\n",
    "2) According to your coefficients, how did `lead_time` influence the probability that a booking would be cancelled? \n",
    "\n",
    "...\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
